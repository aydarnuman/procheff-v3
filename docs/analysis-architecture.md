# Analysis Architecture Documentation

## Ä°Ã§indekiler
1. [Sistem Felsefesi](#1-sistem-felsefesi)
2. [Veri AkÄ±ÅŸ Mimarisi](#2-veri-akÄ±ÅŸ-mimarisi)
3. [ModÃ¼l DÃ¶kÃ¼mantasyonu](#3-modÃ¼l-dÃ¶kÃ¼mantasyonu)
4. [Ä°ÅŸleme HattÄ± DetaylarÄ±](#4-iÅŸleme-hattÄ±-detaylarÄ±)
5. [Hata YÃ¶netimi ve Kurtarma](#5-hata-yÃ¶netimi-ve-kurtarma)
6. [UI DavranÄ±ÅŸ Modeli](#6-ui-davranÄ±ÅŸ-modeli)
7. [YapÄ±landÄ±rma ve Ortam](#7-yapÄ±landÄ±rma-ve-ortam)
8. [GeliÅŸtirme KÄ±lavuzlarÄ±](#8-geliÅŸtirme-kÄ±lavuzlarÄ±)

---

## 1. Sistem Felsefesi

### Temel Ä°lke
**"AI karar vermez, neden o sonuca vardÄ±ÄŸÄ±nÄ± anlatÄ±r"**

Bu sistem, yapay zekanÄ±n bir karar verici deÄŸil, bir analiz aracÄ± olarak kullanÄ±ldÄ±ÄŸÄ± bir mimari Ã¼zerine kurulmuÅŸtur. Her AI Ã§Ä±ktÄ±sÄ± ÅŸeffaf, denetlenebilir ve geri alÄ±nabilir olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

### Ä°nsan Kontrol NoktalarÄ±
1. **Dosya DoÄŸrulama**: YÃ¼klenen her dosya kullanÄ±cÄ± tarafÄ±ndan Ã¶nizlenir
2. **Ä°ÅŸleme OnayÄ±**: Analiz baÅŸlatmadan Ã¶nce kullanÄ±cÄ± onayÄ± gerekir
3. **Analiz Ä°ncelemesi**: Her analiz katmanÄ± ayrÄ± ayrÄ± incelenebilir

### ÅeffaflÄ±k KatmanlarÄ±
- **DataPool**: Ham veri ve Ã§Ä±karÄ±mlar
- **Contextual**: YapÄ±landÄ±rÄ±lmÄ±ÅŸ iÃ§gÃ¶rÃ¼ler
- **Deep Analysis**: Stratejik deÄŸerlendirmeler

### Mimari Hedefler
- âœ… **AÃ§Ä±klanabilir**: Her sonucun arkasÄ±ndaki mantÄ±k gÃ¶rÃ¼nÃ¼r
- âœ… **Denetlenebilir**: TÃ¼m iÅŸlemler loglanÄ±r ve izlenebilir
- âœ… **Geri AlÄ±nabilir**: Her aÅŸama baÄŸÄ±msÄ±z Ã§alÄ±ÅŸÄ±r ve tekrarlanabilir
- âœ… **Ä°nsan Merkezli**: Kritik kararlar her zaman insana bÄ±rakÄ±lÄ±r

---

## 2. Veri AkÄ±ÅŸ Mimarisi

### Genel AkÄ±ÅŸ DiyagramÄ±

```mermaid
graph TD
    A[Dosya YÃ¼kleme] --> B[Smart Detection]
    B --> C[Gemini Classification]
    B --> D[Validation]
    C --> E[UI Preview]
    D --> F[Extraction]
    F --> G[DataPool Building]
    E --> H[Processing Queue]
    H --> I[User Confirmation]
    I --> J[Contextual Analysis]
    I --> K[Deep Analysis]
    J --> L[Final DataPool]
    K --> L
    
    style A fill:#4F46E5,stroke:#312E81,color:#fff
    style I fill:#059669,stroke:#047857,color:#fff
    style L fill:#DC2626,stroke:#B91C1C,color:#fff
```

### DetaylÄ± BileÅŸen EtkileÅŸimi

```mermaid
sequenceDiagram
    participant U as User
    participant UI as UltimateFileUploader
    participant SD as SmartDetection
    participant G as Gemini API
    participant API as Process API
    participant DB as Database
    participant C as Claude API
    
    U->>UI: Dosya yÃ¼kle
    UI->>UI: SHA-256 duplicate check
    UI->>SD: Dosya analizi baÅŸlat
    SD->>G: SÄ±nÄ±flandÄ±rma isteÄŸi
    G-->>SD: documentType, confidence, tags
    SD-->>UI: SmartDetection sonucu
    UI->>U: Ã–nizleme gÃ¶ster
    U->>UI: Ä°ÅŸlemeyi onayla
    UI->>API: POST /api/analysis/process-single
    API->>API: Extract text/tables
    API->>DB: DataPool kaydet
    API-->>UI: SSE stream (progress)
    UI->>U: Ä°lerleme gÃ¶ster
    U->>UI: Analiz baÅŸlat
    UI->>API: POST /api/analysis/contextual
    API->>C: BaÄŸlamsal analiz
    C-->>API: Structured JSON
    API->>DB: Analiz sonucu kaydet
    API-->>UI: Analiz tamamlandÄ±
    UI->>U: SonuÃ§larÄ± gÃ¶ster
```

### DataPool Veri AkÄ±ÅŸÄ±

```mermaid
graph LR
    subgraph "Dosya Ä°ÅŸleme"
        F1[PDF] --> E1[pdfjs-dist]
        F2[DOCX] --> E2[mammoth]
        F3[Excel] --> E3[xlsx]
        F4[CSV] --> E4[CSV Parser]
        F5[ZIP] --> E5[jszip]
    end
    
    subgraph "Veri Ã‡Ä±karÄ±mÄ±"
        E1 --> T[Text Blocks]
        E2 --> T
        E3 --> TB[Tables]
        E4 --> TB
        E5 --> R[Recursive Extract]
    end
    
    subgraph "DataPool"
        T --> DP[DataPool Builder]
        TB --> DP
        R --> DP
        DP --> D[Dates]
        DP --> A[Amounts]
        DP --> EN[Entities]
        DP --> M[Metadata]
    end
    
    subgraph "Analiz"
        DP --> CA[Contextual Analysis]
        CA --> DA[Deep Analysis]
        DA --> FD[Final DataPool]
    end
```

### DetaylÄ± AkÄ±ÅŸ Tablosu

| AÅŸama | Girdi | Ä°ÅŸlem | Ã‡Ä±ktÄ± | Kontrol |
|-------|-------|-------|-------|---------|
| Upload | File[] | MIME type kontrolÃ¼ | FileItem[] | KullanÄ±cÄ± seÃ§imi |
| Smart Detection | File | Heuristik + AI analiz | SmartDetection | Otomatik |
| Validation | FileItem | Format ve boyut kontrolÃ¼ | ValidatedFile | Otomatik |
| Extraction | ValidatedFile | Text/tablo Ã§Ä±karÄ±mÄ± | ExtractedData | Progress tracking |
| DataPool | ExtractedData[] | Veri birleÅŸtirme | DataPool | KullanÄ±cÄ± onayÄ± |
| Contextual | DataPool | Claude analizi | ContextualAnalysis | Manuel tetikleme |
| Deep | DataPool + Context | Derin AI analizi | DeepAnalysis | Manuel tetikleme |

---

## 3. ModÃ¼l DÃ¶kÃ¼mantasyonu

### 3.1 Temel Ä°ÅŸleme ModÃ¼lleri

#### [`src/lib/ai/smart-detection.ts`](../src/lib/ai/smart-detection.ts)
**AmaÃ§**: Dosya tÃ¼rÃ¼ tespiti ve iÃ§erik analizi

```typescript
export class AIDocumentDetector {
  static async detect(file: File): Promise<SmartDetection> {
    // 1. Heuristik analiz
    const textSample = await this.extractTextSample(file);
    let documentType = this.detectDocumentType(textSample);
    let confidence = this.calculateConfidence(textSample, documentType);
    
    // 2. Gemini AI desteÄŸi
    try {
      const geminiResult = await GeminiDocumentClassifier.classify(
        file.name, 
        textSample
      );
      if (geminiResult && geminiResult.confidence > confidence) {
        documentType = geminiResult.documentType;
        confidence = geminiResult.confidence;
      }
    } catch (e) {
      AILogger.warn('Gemini classification failed, using heuristics');
    }
    
    return { documentType, confidence, ...otherMetrics };
  }
}
```

#### [`src/lib/ai/gemini-document-classifier.ts`](../src/lib/ai/gemini-document-classifier.ts)
**AmaÃ§**: Gemini 1.5 Pro ile akÄ±llÄ± dokÃ¼man sÄ±nÄ±flandÄ±rma

```typescript
export interface GeminiClassificationResult {
  documentType: 'Ä°hale Ä°lanÄ±' | 'Ä°dari Åartname' | 'Teknik Åartname' | 
                'Zeyilname' | 'SÃ¶zleÅŸme TaslaÄŸÄ±' | 'Fatura' | 
                'MenÃ¼' | 'Rapor' | 'Teklif' | 'DiÄŸer';
  confidence: number; // 0-100
  tags: string[];
}
```

#### [`src/lib/document-processor/extractor.ts`](../src/lib/document-processor/extractor.ts)
**AmaÃ§**: Ã‡oklu format desteÄŸi ile veri Ã§Ä±karÄ±mÄ±

Desteklenen formatlar:
- PDF (pdfjs-dist)
- DOCX/DOC (mammoth)
- XLSX/XLS (xlsx)
- CSV (Ã¶zel parser)
- TXT/RTF (text decoder)
- HTML (cheerio)
- JSON (native)
- ZIP (jszip - recursive extraction)

#### [`src/lib/document-processor/data-pool.ts`](../src/lib/document-processor/data-pool.ts)
**AmaÃ§**: BirleÅŸtirilmiÅŸ veri havuzu oluÅŸturma

```typescript
export async function buildDataPool(
  files: File[],
  options: ProcessingOptions,
  onProgress?: ProgressCallback
): Promise<ProcessingResult> {
  // 1. ZIP dosyalarÄ±nÄ± aÃ§
  // 2. TÃ¼m dosyalarÄ± iÅŸle
  // 3. Veriyi birleÅŸtir ve doÄŸrula
  // 4. Metadata oluÅŸtur
}
```

### 3.2 Analiz KatmanlarÄ±

#### [`src/lib/tender-analysis/contextual.ts`](../src/lib/tender-analysis/contextual.ts)
**AmaÃ§**: YapÄ±landÄ±rÄ±lmÄ±ÅŸ alan Ã§Ä±karÄ±mÄ± ve risk analizi

```typescript
export async function performContextualAnalysis(
  dataPool: DataPool,
  extractedFields: ExtractedFields
): Promise<ContextualAnalysis> {
  const prompt = buildContextualPrompt(dataPool, extractedFields);
  const result = await AIProviderFactory.createStructuredMessage(
    prompt,
    CONTEXTUAL_ANALYSIS_SCHEMA
  );
  return result.data;
}
```

#### [`src/app/api/analysis/process-single/route.ts`](../src/app/api/analysis/process-single/route.ts)
**AmaÃ§**: Tek dosya iÅŸleme pipeline'Ä± (SSE stream)

```typescript
// Server-Sent Events ile gerÃ§ek zamanlÄ± ilerleme
const stream = new SSEStream();
stream.sendProgress('Dosya iÅŸleniyor...', 10);
stream.sendProgress('Metin Ã§Ä±karÄ±lÄ±yor...', 30);
stream.sendProgress('Tablolar analiz ediliyor...', 60);
stream.sendSuccess({ dataPool, metrics });
```

#### [`src/app/api/analysis/start/route.ts`](../src/app/api/analysis/start/route.ts)
**AmaÃ§**: Ã‡oklu dosya analizi baÅŸlatma

### 3.3 UI BileÅŸenleri

#### [`src/app/analysis/components/UltimateFileUploader.tsx`](../src/app/analysis/components/UltimateFileUploader.tsx)
**AmaÃ§**: Modern dosya yÃ¼kleme deneyimi

Ã–zellikler:
- Drag & drop desteÄŸi
- KlasÃ¶r yÃ¼kleme
- Duplicate kontrolÃ¼ (SHA-256)
- GerÃ§ek zamanlÄ± ilerleme
- PDF thumbnail Ã¶nizleme
- AkÄ±llÄ± dosya gruplama

#### [`src/app/analysis/[id]/page.tsx`](../src/app/analysis/[id]/page.tsx)
**AmaÃ§**: 3 sekmeli analiz gÃ¶rÃ¼nÃ¼mÃ¼

Sekmeler:
1. **Veri Havuzu**: Ham veriler, aranabilir
2. **BaÄŸlamsal**: YapÄ±landÄ±rÄ±lmÄ±ÅŸ iÃ§gÃ¶rÃ¼ler
3. **Derin**: Stratejik tavsiyeler

#### [`src/components/analysis/RawDataView.tsx`](../src/components/analysis/RawDataView.tsx)
**AmaÃ§**: Ham veri gÃ¶rselleÅŸtirme ve arama

---

## 4. Ä°ÅŸleme HattÄ± DetaylarÄ±

### AÅŸama 1: Smart Detection
```typescript
interface SmartDetection {
  documentType: string;        // AI tarafÄ±ndan belirlenen tÃ¼r
  confidence: number;          // 0-100 gÃ¼ven skoru
  suggestedCategory: string;   // Kategori Ã¶nerisi
  autoTags: string[];         // Otomatik etiketler
  language: 'TR' | 'EN' | 'OTHER';
  quality: 'YÃ¼ksek' | 'Orta' | 'DÃ¼ÅŸÃ¼k';
  contentSummary: string;      // Ä°lk 200 karakter
  keyEntities: string[];       // Ã–nemli varlÄ±klar
  estimatedProcessTime: number; // Tahmini sÃ¼re (ms)
}
```

### AÅŸama 2: Extraction
Metin yoÄŸunluÄŸu kontrolÃ¼:
- PDF: %30'dan az metin â†’ OCR fallback
- DOCX: BoÅŸ paragraf kontrolÃ¼
- Excel: BoÅŸ hÃ¼cre oranÄ±

### AÅŸama 3: DataPool Building
```typescript
interface DataPool {
  documents: DocumentInfo[]     // Dosya metadata
  textBlocks: TextBlock[]       // Metin parÃ§alarÄ±
  tables: ExtractedTable[]      // YapÄ±landÄ±rÄ±lmÄ±ÅŸ tablolar
  dates: ExtractedDate[]        // Zaman Ã§izelgesi
  amounts: ExtractedAmount[]    // Finansal veriler
  entities: ExtractedEntity[]   // Kurum, kiÅŸi, yer
  rawText: string              // Ham metin (arama iÃ§in)
  metadata: {
    total_files: number
    total_words: number
    total_pages: number
    creation_date: string
    file_types: string[]
    ocr_used: boolean
    languages_detected: string[]
    warnings: string[]
  }
  provenance: Map<string, SourceLocation>
}
```

### AÅŸama 4: Contextual Analysis
Claude Sonnet 4.5 ile yapÄ±landÄ±rÄ±lmÄ±ÅŸ Ã§Ä±ktÄ±:

```typescript
interface ContextualAnalysis {
  ihale_bilgileri: {
    kurum: string
    ihale_turu: string
    tahmini_bedel: string
    sure: string
    kisilik: number
  }
  operasyonel_riskler: {
    seviye: 'dÃ¼ÅŸÃ¼k' | 'orta' | 'yÃ¼ksek'
    faktorler: RiskFactor[]
  }
  maliyet_analizi: {
    gunluk_kisi_basi: string
    toplam_tahmini: string
    kar_marji_onerisi: string
  }
  uyum_kontrol: {
    eksik_belgeler: string[]
    yasal_uyarilar: string[]
  }
  genel_degerlendirme: {
    puan: number // 0-100
    yorum: string
    oneriler: string[]
  }
}
```

### AÅŸama 5: Deep Analysis
BaÄŸlamsal analiz + piyasa verileri birleÅŸtirilerek:
- Stratejik Ã¶neriler
- Rekabet analizi
- Uygulama yol haritasÄ±
- Risk matrisi

### Analiz KatmanlarÄ± Mimarisi

```mermaid
graph TB
    subgraph "Veri KatmanÄ±"
        DP[DataPool]
        DB[(SQLite DB)]
        Cache[Redis/Memory Cache]
    end
    
    subgraph "Ä°ÅŸleme KatmanÄ±"
        EX[Extractor]
        VAL[Validator]
        TRANS[Transformer]
    end
    
    subgraph "AI KatmanÄ±"
        G[Gemini 1.5 Pro<br/>Classification]
        C1[Claude Sonnet 4.5<br/>Contextual]
        C2[Claude Sonnet 4.5<br/>Deep Analysis]
        O[OpenAI GPT-4<br/>Fallback]
    end
    
    subgraph "API KatmanÄ±"
        REST[REST API]
        SSE[SSE Stream]
        WS[WebSocket<br/>Future]
    end
    
    subgraph "UI KatmanÄ±"
        UP[File Upload]
        AN[Analysis View]
        EXP[Export]
    end
    
    DP --> EX
    EX --> VAL
    VAL --> TRANS
    TRANS --> G
    TRANS --> C1
    C1 --> C2
    
    G --> DB
    C1 --> DB
    C2 --> DB
    
    DB --> Cache
    Cache --> REST
    REST --> SSE
    
    SSE --> UP
    SSE --> AN
    AN --> EXP
    
    style G fill:#4285F4,stroke:#1A73E8,color:#fff
    style C1 fill:#9333EA,stroke:#7C3AED,color:#fff
    style C2 fill:#9333EA,stroke:#7C3AED,color:#fff
    style O fill:#10B981,stroke:#059669,color:#fff
```

---

## 5. Hata YÃ¶netimi ve Kurtarma

### 5.1 DoÄŸrulama HatalarÄ±

| Hata Tipi | Sebep | Ã‡Ã¶zÃ¼m | KullanÄ±cÄ± MesajÄ± |
|-----------|-------|-------|------------------|
| UNSUPPORTED_FORMAT | Desteklenmeyen dosya | Format listesi gÃ¶ster | "Bu format desteklenmiyor. Desteklenen: PDF, DOCX..." |
| FILE_TOO_LARGE | >100MB dosya | Chunk upload Ã¶ner | "Dosya Ã§ok bÃ¼yÃ¼k. ParÃ§alÄ± yÃ¼kleme kullanÄ±n" |
| CORRUPTED_FILE | Bozuk dosya | OCR fallback dene | "Dosya bozuk gÃ¶rÃ¼nÃ¼yor. OCR ile deneniyor..." |
| EMPTY_FILE | BoÅŸ dosya | Red et | "Dosya boÅŸ veya okunamÄ±yor" |

### 5.2 Ä°ÅŸleme HatalarÄ±

```typescript
// Exponential backoff ile retry
async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  maxRetries = 3,
  baseDelay = 1000
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      const delay = baseDelay * Math.pow(1.5, i);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  throw new Error('Max retries exceeded');
}
```

### 5.3 KÄ±smi BaÅŸarÄ±sÄ±zlÄ±k YÃ¶netimi

```typescript
interface ProcessingResult {
  success: boolean;
  dataPool: DataPool;
  errors: ProcessingError[];
  warnings: string[];
  metadata: {
    total_files: number;
    processed_files: number;
    failed_files: number;
    extraction_time_ms: number;
  };
}
```

### 5.4 Hata AkÄ±ÅŸ DiyagramÄ±

```mermaid
flowchart TD
    Start([Dosya Ä°ÅŸleme BaÅŸla]) --> Check{Format Destekleniyor mu?}
    Check -->|HayÄ±r| FormatError[Format HatasÄ±]
    Check -->|Evet| Extract[Veri Ã‡Ä±karÄ±mÄ±]
    
    Extract --> ExtractCheck{Ã‡Ä±karÄ±m BaÅŸarÄ±lÄ± mÄ±?}
    ExtractCheck -->|HayÄ±r| OCRCheck{PDF mi?}
    OCRCheck -->|Evet| OCR[OCR Fallback]
    OCRCheck -->|HayÄ±r| ExtractError[Ã‡Ä±karÄ±m HatasÄ±]
    
    ExtractCheck -->|Evet| Validate[Veri DoÄŸrulama]
    OCR --> Validate
    
    Validate --> ValidCheck{Veri GeÃ§erli mi?}
    ValidCheck -->|HayÄ±r| ValidationError[DoÄŸrulama HatasÄ±]
    ValidCheck -->|Evet| Save[DataPool Kaydet]
    
    Save --> SaveCheck{KayÄ±t BaÅŸarÄ±lÄ± mÄ±?}
    SaveCheck -->|HayÄ±r| Retry{Retry < 3?}
    Retry -->|Evet| Save
    Retry -->|HayÄ±r| SaveError[KayÄ±t HatasÄ±]
    SaveCheck -->|Evet| Success([BaÅŸarÄ±lÄ±])
    
    FormatError --> Log[Hata Logla]
    ExtractError --> Log
    ValidationError --> Log
    SaveError --> Log
    Log --> PartialSuccess{DiÄŸer Dosyalar Var mÄ±?}
    PartialSuccess -->|Evet| NextFile[Sonraki Dosya]
    PartialSuccess -->|HayÄ±r| Report[Rapor OluÅŸtur]
    NextFile --> Start
    
    style Success fill:#10B981,stroke:#047857,color:#fff
    style FormatError fill:#EF4444,stroke:#B91C1C,color:#fff
    style ExtractError fill:#EF4444,stroke:#B91C1C,color:#fff
    style ValidationError fill:#EF4444,stroke:#B91C1C,color:#fff
    style SaveError fill:#EF4444,stroke:#B91C1C,color:#fff
    style OCR fill:#F59E0B,stroke:#D97706,color:#fff
```

---

## 6. UI DavranÄ±ÅŸ Modeli

### 6.1 Dosya YÃ¼kleme AkÄ±ÅŸÄ±

```mermaid
stateDiagram-v2
    [*] --> DragDrop: KullanÄ±cÄ± dosya seÃ§er
    DragDrop --> DuplicateCheck: Dosya bÄ±rakÄ±ldÄ±
    DuplicateCheck --> SmartDetection: Yeni dosya
    DuplicateCheck --> Warning: Duplicate tespit
    SmartDetection --> Preview: AI sÄ±nÄ±flandÄ±rma
    Preview --> Queue: KullanÄ±cÄ± onayÄ±
    Queue --> Processing: Ä°ÅŸleme baÅŸla
    Processing --> Success: TamamlandÄ±
    Processing --> Error: Hata
    Error --> Retry: Tekrar dene
    Success --> [*]
```

### 6.2 Ä°lerleme GÃ¶rselleÅŸtirme

Her dosya iÃ§in 5 aÅŸamalÄ± ilerleme:
1. **DoÄŸrulama** (0-20%): Format ve boyut kontrolÃ¼
2. **Ã‡Ä±karÄ±m** (20-50%): Metin ve tablo Ã§Ä±karÄ±mÄ±
3. **Analiz** (50-70%): AI sÄ±nÄ±flandÄ±rma
4. **BirleÅŸtirme** (70-90%): DataPool oluÅŸturma
5. **Tamamlama** (90-100%): Metadata ve indeksleme

```mermaid
graph LR
    subgraph "Ä°lerleme AÅŸamalarÄ±"
        S1[0-20%<br/>DoÄŸrulama] --> S2[20-50%<br/>Ã‡Ä±karÄ±m]
        S2 --> S3[50-70%<br/>AI Analiz]
        S3 --> S4[70-90%<br/>BirleÅŸtirme]
        S4 --> S5[90-100%<br/>Tamamlama]
    end
    
    style S1 fill:#FEF3C7,stroke:#F59E0B,color:#000
    style S2 fill:#DBEAFE,stroke:#3B82F6,color:#000
    style S3 fill:#E9D5FF,stroke:#9333EA,color:#000
    style S4 fill:#D1FAE5,stroke:#10B981,color:#000
    style S5 fill:#FEE2E2,stroke:#EF4444,color:#000
```

### 6.3 Analiz GÃ¶rÃ¼nÃ¼mÃ¼

#### Tab 1 - Veri Havuzu
- **Ã–zet Kartlar**: DokÃ¼man, tablo, tarih, tutar sayÄ±larÄ±
- **Arama**: Full-text arama tÃ¼m veride
- **Filtreleme**: Dosya tÃ¼rÃ¼, tarih aralÄ±ÄŸÄ±
- **DÄ±ÅŸa AktarÄ±m**: CSV, JSON formatlarÄ±

#### Tab 2 - BaÄŸlamsal
- **Risk Matrisi**: GÃ¶rsel risk haritasÄ±
- **Kritik Bilgiler**: Highlight edilmiÅŸ Ã¶nemli veriler
- **Uyum Kontrol**: Eksik belge listesi
- **Maliyet Ã–zeti**: DetaylÄ± maliyet daÄŸÄ±lÄ±mÄ±

#### Tab 3 - Derin
- **Strateji Ã–nerileri**: Aksiyona dÃ¶nÃ¼k tavsiyeler
- **SWOT Analizi**: GÃ¼Ã§lÃ¼/zayÄ±f yÃ¶nler
- **Zaman Ã‡izelgesi**: Kritik tarihler
- **Karar Destek**: Pros/cons listesi

---

## 7. YapÄ±landÄ±rma ve Ortam

### 7.1 Gerekli API AnahtarlarÄ±

```bash
# .env.local
ANTHROPIC_API_KEY=sk-ant-api03-xxxxx    # Claude Sonnet 4.5
GOOGLE_API_KEY=AIzaSyxxxxx              # Gemini 1.5 Pro
OPENAI_API_KEY=sk-xxxxx                 # GPT-4 (opsiyonel)
```

### 7.2 Performans AyarlarÄ±

```typescript
// config/analysis.ts
export const ANALYSIS_CONFIG = {
  MAX_FILE_SIZE: 100 * 1024 * 1024,      // 100MB
  MAX_FILES_PER_UPLOAD: 50,               // Tek seferde max dosya
  CONCURRENT_UPLOADS: 5,                  // Paralel yÃ¼kleme
  CHUNK_SIZE: 5 * 1024 * 1024,           // 5MB chunk
  ANALYSIS_TIMEOUT: 300_000,              // 5 dakika
  CACHE_TTL: 24 * 60 * 60 * 1000,        // 24 saat
  OCR_CONFIDENCE_THRESHOLD: 0.7,          // OCR gÃ¼ven eÅŸiÄŸi
  MIN_TEXT_DENSITY: 0.3,                  // Min metin yoÄŸunluÄŸu
};
```

### 7.3 VeritabanÄ± KonfigÃ¼rasyonu

```sql
-- SQLite ÅŸema Ã¶zeti
CREATE TABLE data_pools (
  id TEXT PRIMARY KEY,
  session_id TEXT NOT NULL,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  data BLOB NOT NULL,
  metadata JSON,
  version INTEGER DEFAULT 1
);

CREATE TABLE analysis_history (
  id TEXT PRIMARY KEY,
  analysis_id TEXT NOT NULL,
  stage TEXT NOT NULL,
  input_data JSON,
  output_data JSON,
  duration_ms INTEGER,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_session ON data_pools(session_id);
CREATE INDEX idx_analysis ON analysis_history(analysis_id);
```

---

## 8. GeliÅŸtirme KÄ±lavuzlarÄ±

### 8.1 Yeni DokÃ¼man Tipi Ekleme

#### Ã–rnek: "GÃ¼venlik Raporu" Tipi Ekleme

1. **Smart Detection GÃ¼ncelleme**
```typescript
// src/lib/ai/smart-detection.ts
private static readonly TYPE_KEYWORDS: Record<string, string[]> = {
  'Ä°hale Ä°lanÄ±': ['ihale', 'ilan', 'duyuru', 'ihale ilanÄ±', 'kamu ihale'],
  'Ä°dari Åartname': ['idari ÅŸartname', 'idari', 'ÅŸartname'],
  'Teknik Åartname': ['teknik ÅŸartname', 'teknik', 'Ã¶zellikler'],
  'GÃ¼venlik Raporu': ['gÃ¼venlik', 'gÃ¼venlik raporu', 'risk deÄŸerlendirme', 'tehdit analizi'], // YENÄ°
};

// Kategori eÅŸleÅŸtirmesi gÃ¼ncelle
private static readonly CATEGORY_MAP: Record<string, string> = {
  'Ä°hale Ä°lanÄ±': 'Ä°hale DokÃ¼manlarÄ±',
  'GÃ¼venlik Raporu': 'Risk ve GÃ¼venlik', // YENÄ°
  // ...
};
```

2. **Gemini Prompt GÃ¼ncelleme**
```typescript
// src/lib/ai/gemini-document-classifier.ts
export interface GeminiClassificationResult {
  documentType: 'Ä°hale Ä°lanÄ±' | 'Ä°dari Åartname' | 'Teknik Åartname' | 
                'Zeyilname' | 'SÃ¶zleÅŸme TaslaÄŸÄ±' | 'Fatura' | 
                'MenÃ¼' | 'Rapor' | 'Teklif' | 'GÃ¼venlik Raporu' | 'DiÄŸer'; // YENÄ°
  confidence: number;
  tags: string[];
}

const CLASSIFICATION_PROMPT = `
Sen bir ihale dokÃ¼manÄ± sÄ±nÄ±flandÄ±rma asistanÄ±sÄ±n. 
OlasÄ± documentType deÄŸerleri: 'Ä°hale Ä°lanÄ±', 'Ä°dari Åartname', 'Teknik Åartname', 
'Zeyilname', 'SÃ¶zleÅŸme TaslaÄŸÄ±', 'Fatura', 'MenÃ¼', 'Rapor', 'Teklif', 
'GÃ¼venlik Raporu', 'DiÄŸer'.

GÃ¼venlik Raporu Ã¶zellikleri:
- Risk deÄŸerlendirmesi iÃ§erir
- Tehdit analizi bulunur
- GÃ¼venlik Ã¶nlemleri listelenir
- Acil durum prosedÃ¼rleri vardÄ±r
`;
```

3. **Ã–zel Extraction Logic (Opsiyonel)**
```typescript
// src/lib/document-processor/security-report-extractor.ts
export async function extractSecurityMetrics(
  textBlocks: TextBlock[],
  tables: ExtractedTable[]
): Promise<SecurityMetrics> {
  const metrics: SecurityMetrics = {
    riskLevel: 'unknown',
    threats: [],
    mitigations: [],
    complianceStatus: []
  };
  
  // Risk seviyesi tespiti
  const riskPatterns = /risk (seviyesi|level):\s*(dÃ¼ÅŸÃ¼k|orta|yÃ¼ksek|kritik)/gi;
  for (const block of textBlocks) {
    const match = riskPatterns.exec(block.content);
    if (match) {
      metrics.riskLevel = match[2].toLowerCase() as RiskLevel;
    }
  }
  
  // Tehdit listesi Ã§Ä±karÄ±mÄ±
  const threatSection = textBlocks.find(b => 
    b.content.toLowerCase().includes('tehdit') || 
    b.content.toLowerCase().includes('risk faktÃ¶r')
  );
  
  if (threatSection) {
    // Madde iÅŸaretli liste parse et
    const threats = threatSection.content
      .split('\n')
      .filter(line => line.match(/^[-â€¢*]\s+/))
      .map(line => line.replace(/^[-â€¢*]\s+/, '').trim());
    
    metrics.threats = threats;
  }
  
  return metrics;
}
```

### 8.2 Yeni Analiz KatmanÄ± Ekleme

#### Ã–rnek: "SÃ¼rdÃ¼rÃ¼lebilirlik Analizi" KatmanÄ±

1. **Type TanÄ±mlarÄ± ve Åema**
```typescript
// src/lib/tender-analysis/types.ts
export interface SustainabilityAnalysis {
  environmental_impact: {
    carbon_footprint: string;
    waste_management: string;
    energy_efficiency: number; // 0-100
    green_materials_ratio: number; // 0-100
  };
  social_impact: {
    local_employment: number;
    worker_safety_score: number; // 0-100
    community_benefit: string[];
  };
  economic_sustainability: {
    long_term_viability: 'dÃ¼ÅŸÃ¼k' | 'orta' | 'yÃ¼ksek';
    local_supplier_ratio: number; // 0-100
    lifecycle_cost_analysis: string;
  };
  recommendations: string[];
  overall_score: number; // 0-100
}

// Zod ÅŸema validasyonu
import { z } from 'zod';

export const SustainabilityAnalysisSchema = z.object({
  environmental_impact: z.object({
    carbon_footprint: z.string(),
    waste_management: z.string(),
    energy_efficiency: z.number().min(0).max(100),
    green_materials_ratio: z.number().min(0).max(100)
  }),
  social_impact: z.object({
    local_employment: z.number().min(0),
    worker_safety_score: z.number().min(0).max(100),
    community_benefit: z.array(z.string())
  }),
  economic_sustainability: z.object({
    long_term_viability: z.enum(['dÃ¼ÅŸÃ¼k', 'orta', 'yÃ¼ksek']),
    local_supplier_ratio: z.number().min(0).max(100),
    lifecycle_cost_analysis: z.string()
  }),
  recommendations: z.array(z.string()),
  overall_score: z.number().min(0).max(100)
});
```

2. **AI Prompt ve Schema**
```typescript
// src/lib/ai/prompts/sustainability.ts
export const SUSTAINABILITY_ANALYSIS_PROMPT = `
Sen sÃ¼rdÃ¼rÃ¼lebilirlik uzmanÄ± olarak Ã§alÄ±ÅŸan bir AI asistanÄ±sÄ±n.
Sana verilen ihale dokÃ¼manlarÄ±nÄ± Ã§evresel, sosyal ve ekonomik sÃ¼rdÃ¼rÃ¼lebilirlik 
aÃ§Ä±sÄ±ndan analiz edeceksin.

DeÄŸerlendirme Kriterleri:
1. Ã‡evresel Etki: Karbon ayak izi, atÄ±k yÃ¶netimi, enerji verimliliÄŸi
2. Sosyal Etki: Yerel istihdam, iÅŸÃ§i gÃ¼venliÄŸi, toplumsal fayda
3. Ekonomik SÃ¼rdÃ¼rÃ¼lebilirlik: Uzun vadeli uygulanabilirlik, yerel tedarikÃ§i kullanÄ±mÄ±

Puanlama:
- 0-40: DÃ¼ÅŸÃ¼k sÃ¼rdÃ¼rÃ¼lebilirlik
- 41-70: Orta sÃ¼rdÃ¼rÃ¼lebilirlik  
- 71-100: YÃ¼ksek sÃ¼rdÃ¼rÃ¼lebilirlik

YanÄ±tÄ±nÄ± aÅŸaÄŸÄ±daki JSON formatÄ±nda ver:
`;

export const SUSTAINABILITY_SCHEMA = {
  name: "sustainability_analysis",
  schema: {
    type: "object",
    properties: {
      environmental_impact: {
        type: "object",
        properties: {
          carbon_footprint: { type: "string" },
          waste_management: { type: "string" },
          energy_efficiency: { type: "number", minimum: 0, maximum: 100 },
          green_materials_ratio: { type: "number", minimum: 0, maximum: 100 }
        },
        required: ["carbon_footprint", "waste_management", "energy_efficiency", "green_materials_ratio"]
      },
      social_impact: {
        type: "object",
        properties: {
          local_employment: { type: "number", minimum: 0 },
          worker_safety_score: { type: "number", minimum: 0, maximum: 100 },
          community_benefit: { type: "array", items: { type: "string" } }
        },
        required: ["local_employment", "worker_safety_score", "community_benefit"]
      },
      economic_sustainability: {
        type: "object",
        properties: {
          long_term_viability: { type: "string", enum: ["dÃ¼ÅŸÃ¼k", "orta", "yÃ¼ksek"] },
          local_supplier_ratio: { type: "number", minimum: 0, maximum: 100 },
          lifecycle_cost_analysis: { type: "string" }
        },
        required: ["long_term_viability", "local_supplier_ratio", "lifecycle_cost_analysis"]
      },
      recommendations: { type: "array", items: { type: "string" } },
      overall_score: { type: "number", minimum: 0, maximum: 100 }
    },
    required: ["environmental_impact", "social_impact", "economic_sustainability", "recommendations", "overall_score"]
  }
};
```

3. **Analiz Fonksiyonu**
```typescript
// src/lib/tender-analysis/sustainability.ts
import { AIProviderFactory } from '@/lib/ai/provider-factory';
import { SUSTAINABILITY_ANALYSIS_PROMPT, SUSTAINABILITY_SCHEMA } from '@/lib/ai/prompts/sustainability';
import type { DataPool } from '@/lib/document-processor/types';
import type { SustainabilityAnalysis } from './types';

export async function performSustainabilityAnalysis(
  dataPool: DataPool
): Promise<SustainabilityAnalysis> {
  // Ä°lgili veri noktalarÄ±nÄ± Ã§Ä±kar
  const relevantData = extractSustainabilityIndicators(dataPool);
  
  // Prompt oluÅŸtur
  const prompt = `
${SUSTAINABILITY_ANALYSIS_PROMPT}

Ä°hale Bilgileri:
${JSON.stringify(relevantData, null, 2)}

DokÃ¼man Ä°Ã§eriÄŸi:
${dataPool.textBlocks.slice(0, 10).map(b => b.content).join('\n\n')}
`;

  // AI analizi
  const result = await AIProviderFactory.createStructuredMessage<SustainabilityAnalysis>(
    prompt,
    SUSTAINABILITY_SCHEMA,
    {
      model: 'claude-3-5-sonnet-20241022',
      temperature: 0.3,
      maxTokens: 2000
    }
  );
  
  return result.data;
}

function extractSustainabilityIndicators(dataPool: DataPool) {
  const indicators = {
    hasGreenCriteria: false,
    mentionsLocalSuppliers: false,
    hasWasteManagement: false,
    employmentNumbers: [] as number[],
    energyKeywords: [] as string[]
  };
  
  // YeÅŸil kriterler ara
  const greenKeywords = ['yeÅŸil', 'sÃ¼rdÃ¼rÃ¼lebilir', 'Ã§evre dostu', 'enerji verimli', 'geri dÃ¶nÃ¼ÅŸÃ¼m'];
  
  dataPool.textBlocks.forEach(block => {
    const content = block.content.toLowerCase();
    
    // YeÅŸil kriterler
    if (greenKeywords.some(kw => content.includes(kw))) {
      indicators.hasGreenCriteria = true;
    }
    
    // Yerel tedarikÃ§i
    if (content.includes('yerel') && content.includes('tedarik')) {
      indicators.mentionsLocalSuppliers = true;
    }
    
    // Ä°stihdam sayÄ±larÄ±
    const employmentMatch = content.match(/(\d+)\s*kiÅŸi.*istihdam/);
    if (employmentMatch) {
      indicators.employmentNumbers.push(parseInt(employmentMatch[1]));
    }
  });
  
  return indicators;
}
```

4. **API Endpoint**
```typescript
// src/app/api/analysis/sustainability/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { performSustainabilityAnalysis } from '@/lib/tender-analysis/sustainability';
import { AILogger } from '@/lib/ai/logger';
import { errorHandler } from '@/lib/middleware/error-handler';
import { createErrorResponse } from '@/lib/utils/error-codes';

async function handleSustainabilityAnalysis(request: NextRequest) {
  const startTime = Date.now();
  
  try {
    const body = await request.json();
    const { analysisId, dataPool } = body;
    
    if (!analysisId || !dataPool) {
      return NextResponse.json(
        createErrorResponse('INVALID_REQUEST', 'Missing required fields'),
        { status: 400 }
      );
    }
    
    AILogger.info('Starting sustainability analysis', { analysisId });
    
    // Perform analysis
    const sustainabilityAnalysis = await performSustainabilityAnalysis(dataPool);
    
    // Save to database
    const db = getDB();
    db.prepare(`
      INSERT OR REPLACE INTO analysis_results (
        id, analysis_id, stage, result_data, created_at
      ) VALUES (?, ?, ?, ?, datetime('now'))
    `).run(
      `${analysisId}_sustainability`,
      analysisId,
      'sustainability',
      JSON.stringify(sustainabilityAnalysis)
    );
    
    const duration = Date.now() - startTime;
    
    AILogger.success('Sustainability analysis completed', {
      analysisId,
      duration,
      overall_score: sustainabilityAnalysis.overall_score
    });
    
    return NextResponse.json({
      success: true,
      analysisId,
      sustainabilityAnalysis,
      metadata: {
        duration_ms: duration,
        overall_score: sustainabilityAnalysis.overall_score
      }
    });
  } catch (error) {
    AILogger.error('Sustainability analysis failed', { error });
    return NextResponse.json(
      createErrorResponse('ANALYSIS_FAILED', error instanceof Error ? error.message : 'Unknown error'),
      { status: 500 }
    );
  }
}

export const POST = errorHandler(handleSustainabilityAnalysis);
```

5. **UI Component**
```typescript
// src/app/analysis/components/SustainabilityTab.tsx
'use client';

import { useState } from 'react';
import { Leaf, Users, TrendingUp, AlertCircle } from 'lucide-react';
import { motion } from 'framer-motion';
import type { DataPool } from '@/lib/document-processor/types';
import type { SustainabilityAnalysis } from '@/lib/tender-analysis/types';

interface SustainabilityTabProps {
  dataPool: DataPool;
  analysis: SustainabilityAnalysis | null;
  onTriggerAnalysis: () => void;
  loading: boolean;
}

export function SustainabilityTab({ 
  dataPool, 
  analysis, 
  onTriggerAnalysis, 
  loading 
}: SustainabilityTabProps) {
  if (!analysis) {
    return (
      <div className="glass-card p-8 text-center">
        <Leaf className="w-12 h-12 text-green-400 mx-auto mb-4" />
        <h3 className="text-xl font-semibold mb-2">SÃ¼rdÃ¼rÃ¼lebilirlik Analizi</h3>
        <p className="text-slate-400 mb-6">
          Ä°halenin Ã§evresel, sosyal ve ekonomik sÃ¼rdÃ¼rÃ¼lebilirliÄŸini deÄŸerlendirin
        </p>
        <button
          onClick={onTriggerAnalysis}
          disabled={loading}
          className="px-6 py-3 bg-green-500 hover:bg-green-600 rounded-lg transition-colors disabled:opacity-50"
        >
          {loading ? 'Analiz Ediliyor...' : 'Analizi BaÅŸlat'}
        </button>
      </div>
    );
  }
  
  const getScoreColor = (score: number) => {
    if (score >= 70) return 'text-green-400';
    if (score >= 40) return 'text-yellow-400';
    return 'text-red-400';
  };
  
  return (
    <div className="space-y-6">
      {/* Overall Score */}
      <motion.div
        initial={{ opacity: 0, y: 20 }}
        animate={{ opacity: 1, y: 0 }}
        className="glass-card p-6"
      >
        <div className="flex items-center justify-between">
          <h3 className="text-xl font-semibold">Genel SÃ¼rdÃ¼rÃ¼lebilirlik Skoru</h3>
          <div className={`text-4xl font-bold ${getScoreColor(analysis.overall_score)}`}>
            {analysis.overall_score}/100
          </div>
        </div>
      </motion.div>
      
      {/* Environmental Impact */}
      <motion.div
        initial={{ opacity: 0, y: 20 }}
        animate={{ opacity: 1, y: 0 }}
        transition={{ delay: 0.1 }}
        className="glass-card p-6"
      >
        <div className="flex items-center gap-2 mb-4">
          <Leaf className="w-5 h-5 text-green-400" />
          <h4 className="text-lg font-semibold">Ã‡evresel Etki</h4>
        </div>
        <div className="space-y-3">
          <div>
            <div className="flex justify-between mb-1">
              <span className="text-sm text-slate-400">Enerji VerimliliÄŸi</span>
              <span className="text-sm">{analysis.environmental_impact.energy_efficiency}%</span>
            </div>
            <div className="w-full bg-slate-700 rounded-full h-2">
              <div 
                className="bg-green-500 h-2 rounded-full transition-all"
                style={{ width: `${analysis.environmental_impact.energy_efficiency}%` }}
              />
            </div>
          </div>
          <div>
            <span className="text-sm text-slate-400">Karbon Ayak Ä°zi:</span>
            <p className="text-sm mt-1">{analysis.environmental_impact.carbon_footprint}</p>
          </div>
        </div>
      </motion.div>
      
      {/* Recommendations */}
      <motion.div
        initial={{ opacity: 0, y: 20 }}
        animate={{ opacity: 1, y: 0 }}
        transition={{ delay: 0.3 }}
        className="glass-card p-6"
      >
        <h4 className="text-lg font-semibold mb-4">Ã–neriler</h4>
        <ul className="space-y-2">
          {analysis.recommendations.map((rec, idx) => (
            <li key={idx} className="flex items-start gap-2">
              <AlertCircle className="w-4 h-4 text-blue-400 mt-0.5 flex-shrink-0" />
              <span className="text-sm">{rec}</span>
            </li>
          ))}
        </ul>
      </motion.div>
    </div>
  );
}
```

6. **Ana Sayfa Entegrasyonu**
```typescript
// src/app/analysis/[id]/page.tsx iÃ§ine ekle
import { SustainabilityTab } from './components/SustainabilityTab';
import { Leaf } from 'lucide-react';

// State ekle
const [sustainabilityAnalysis, setSustainabilityAnalysis] = useState<SustainabilityAnalysis | null>(null);

// Tab listesine ekle
const tabs = [
  // ... mevcut sekmeler
  {
    id: 'sustainability' as TabType,
    name: 'ğŸŒ± SÃ¼rdÃ¼rÃ¼lebilirlik',
    icon: Leaf,
    color: 'from-green-500 to-teal-500',
    description: 'Ã‡evresel ve sosyal etki analizi'
  }
];

// Trigger fonksiyonu ekle
const triggerSustainabilityAnalysis = async () => {
  if (!dataPool) return;
  
  setAnalysisLoading('sustainability');
  try {
    const response = await fetch('/api/analysis/sustainability', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ analysisId: id, dataPool })
    });
    
    if (response.ok) {
      const data = await response.json();
      setSustainabilityAnalysis(data.sustainabilityAnalysis);
    }
  } catch (error) {
    console.error('Sustainability analysis error:', error);
  } finally {
    setAnalysisLoading(null);
  }
};

// Tab iÃ§eriÄŸine ekle
{activeTab === 'sustainability' && (
  <SustainabilityTab
    dataPool={dataPool}
    analysis={sustainabilityAnalysis}
    onTriggerAnalysis={triggerSustainabilityAnalysis}
    loading={analysisLoading === 'sustainability'}
  />
)}
```

### 8.3 Hata AyÄ±klama ve Ä°zleme

#### Debug Panel Ekleme
```typescript
// src/components/debug/AnalysisDebugPanel.tsx
export function AnalysisDebugPanel({ analysis }: Props) {
  return (
    <div className="glass-card p-4 font-mono text-xs">
      <h3>ğŸ› Debug Info</h3>
      <pre>{JSON.stringify(analysis, null, 2)}</pre>
      <div>Tokens: {analysis.metadata.total_tokens}</div>
      <div>Cost: ${analysis.metadata.cost_usd}</div>
    </div>
  );
}
```

#### Error Snapshot
```typescript
// src/lib/error-tracking.ts
export async function captureAnalysisError(
  error: Error,
  context: Record<string, any>
) {
  const snapshot = {
    timestamp: new Date().toISOString(),
    error: {
      message: error.message,
      stack: error.stack
    },
    context,
    environment: {
      node_version: process.version,
      memory: process.memoryUsage()
    }
  };
  
  await fs.writeFile(
    `logs/error_${Date.now()}.json`,
    JSON.stringify(snapshot, null, 2)
  );
}
```

### 8.4 Performans Optimizasyonu

#### Chunk Processing
```typescript
// BÃ¼yÃ¼k dosyalar iÃ§in chunk processing
async function* processInChunks<T>(
  items: T[],
  chunkSize: number,
  processor: (item: T) => Promise<void>
) {
  for (let i = 0; i < items.length; i += chunkSize) {
    const chunk = items.slice(i, i + chunkSize);
    await Promise.all(chunk.map(processor));
    yield { processed: i + chunk.length, total: items.length };
  }
}
```

#### Caching Strategy
```typescript
// Redis veya in-memory cache
const analysisCache = new Map<string, CachedResult>();

function getCacheKey(dataPool: DataPool): string {
  const content = JSON.stringify(dataPool);
  return crypto.createHash('sha256').update(content).digest('hex');
}

async function getOrCompute<T>(
  key: string,
  compute: () => Promise<T>,
  ttl: number = 3600000 // 1 saat
): Promise<T> {
  const cached = analysisCache.get(key);
  if (cached && cached.expires > Date.now()) {
    return cached.data;
  }
  
  const result = await compute();
  analysisCache.set(key, {
    data: result,
    expires: Date.now() + ttl
  });
  
  return result;
}
```

### 8.5 GÃ¼venlik Kontrolleri

#### Input Validation
```typescript
// Zod ÅŸemalarÄ± ile validasyon
import { z } from 'zod';

const FileUploadSchema = z.object({
  files: z.array(z.instanceof(File)).max(50),
  sessionId: z.string().uuid(),
  options: z.object({
    ocr_enabled: z.boolean().optional(),
    language: z.enum(['tr', 'en']).optional()
  })
});

// KullanÄ±m
const validated = FileUploadSchema.parse(request.body);
```

#### Rate Limiting
```typescript
// API rate limiting
const rateLimiter = new Map<string, number[]>();

export function checkRateLimit(
  clientId: string,
  maxRequests: number = 100,
  windowMs: number = 60000
): boolean {
  const now = Date.now();
  const requests = rateLimiter.get(clientId) || [];
  const recentRequests = requests.filter(t => t > now - windowMs);
  
  if (recentRequests.length >= maxRequests) {
    return false;
  }
  
  recentRequests.push(now);
  rateLimiter.set(clientId, recentRequests);
  return true;
}
```

---

## 9. YaygÄ±n Senaryolar ve Kod Ã–rnekleri

### 9.1 BÃ¼yÃ¼k Dosya Ä°ÅŸleme (Chunk Upload)

```typescript
// src/lib/document-processor/chunk-upload.ts
export class ChunkUploadManager {
  private chunks: Map<string, Uint8Array[]> = new Map();
  
  async uploadChunk(
    fileId: string,
    chunkIndex: number,
    chunk: Uint8Array,
    totalChunks: number
  ): Promise<{ complete: boolean; progress: number }> {
    // Chunk'larÄ± sakla
    if (!this.chunks.has(fileId)) {
      this.chunks.set(fileId, []);
    }
    
    const fileChunks = this.chunks.get(fileId)!;
    fileChunks[chunkIndex] = chunk;
    
    // Ä°lerleme hesapla
    const uploadedChunks = fileChunks.filter(c => c !== undefined).length;
    const progress = (uploadedChunks / totalChunks) * 100;
    
    // TÃ¼m chunk'lar yÃ¼klendi mi?
    if (uploadedChunks === totalChunks) {
      // DosyayÄ± birleÅŸtir
      const completeFile = this.assembleChunks(fileId);
      await this.processCompleteFile(fileId, completeFile);
      
      // Temizle
      this.chunks.delete(fileId);
      
      return { complete: true, progress: 100 };
    }
    
    return { complete: false, progress };
  }
  
  private assembleChunks(fileId: string): Uint8Array {
    const chunks = this.chunks.get(fileId)!;
    const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
    
    const result = new Uint8Array(totalLength);
    let offset = 0;
    
    for (const chunk of chunks) {
      result.set(chunk, offset);
      offset += chunk.length;
    }
    
    return result;
  }
}

// KullanÄ±m Ã¶rneÄŸi
const CHUNK_SIZE = 5 * 1024 * 1024; // 5MB

export async function uploadLargeFile(file: File) {
  const chunks = Math.ceil(file.size / CHUNK_SIZE);
  const fileId = crypto.randomUUID();
  
  for (let i = 0; i < chunks; i++) {
    const start = i * CHUNK_SIZE;
    const end = Math.min(start + CHUNK_SIZE, file.size);
    const chunk = await file.slice(start, end).arrayBuffer();
    
    const formData = new FormData();
    formData.append('fileId', fileId);
    formData.append('chunkIndex', i.toString());
    formData.append('totalChunks', chunks.toString());
    formData.append('chunk', new Blob([chunk]));
    
    const response = await fetch('/api/upload/chunk', {
      method: 'POST',
      body: formData
    });
    
    const result = await response.json();
    console.log(`Chunk ${i + 1}/${chunks} uploaded, progress: ${result.progress}%`);
  }
}
```

### 9.2 GerÃ§ek ZamanlÄ± Ä°lerleme Takibi (SSE)

```typescript
// src/lib/sse/stream.ts
export class SSEStream {
  private encoder = new TextEncoder();
  private stream: ReadableStream;
  private controller: ReadableStreamDefaultController | null = null;
  
  constructor() {
    this.stream = new ReadableStream({
      start: (controller) => {
        this.controller = controller;
      },
      cancel: () => {
        this.controller = null;
      }
    });
  }
  
  sendEvent(event: string, data: any) {
    if (!this.controller) return;
    
    const message = `event: ${event}\ndata: ${JSON.stringify(data)}\n\n`;
    this.controller.enqueue(this.encoder.encode(message));
  }
  
  sendProgress(message: string, progress: number) {
    this.sendEvent('progress', { message, progress });
  }
  
  sendError(error: string, code?: string) {
    this.sendEvent('error', { error, code });
  }
  
  sendSuccess(data: any) {
    this.sendEvent('success', data);
    this.close();
  }
  
  close() {
    this.controller?.close();
  }
  
  getResponse(): Response {
    return new Response(this.stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      }
    });
  }
}

// Client tarafÄ± kullanÄ±mÄ±
export function subscribeToSSE(url: string, handlers: {
  onProgress?: (data: { message: string; progress: number }) => void;
  onError?: (data: { error: string; code?: string }) => void;
  onSuccess?: (data: any) => void;
}) {
  const eventSource = new EventSource(url);
  
  eventSource.addEventListener('progress', (e) => {
    const data = JSON.parse(e.data);
    handlers.onProgress?.(data);
  });
  
  eventSource.addEventListener('error', (e) => {
    const data = JSON.parse(e.data);
    handlers.onError?.(data);
  });
  
  eventSource.addEventListener('success', (e) => {
    const data = JSON.parse(e.data);
    handlers.onSuccess?.(data);
    eventSource.close();
  });
  
  return () => eventSource.close();
}
```

### 9.3 Ã–zel Veri Ã‡Ä±karÄ±cÄ± Ekleme

```typescript
// src/lib/document-processor/custom-extractors/invoice-extractor.ts
import type { ExtractedTable, ExtractedAmount, ExtractedDate } from '../types';

export interface InvoiceData {
  invoiceNumber: string;
  date: Date;
  vendor: string;
  totalAmount: number;
  lineItems: Array<{
    description: string;
    quantity: number;
    unitPrice: number;
    total: number;
  }>;
  taxDetails: {
    subtotal: number;
    taxRate: number;
    taxAmount: number;
    grandTotal: number;
  };
}

export async function extractInvoiceData(
  tables: ExtractedTable[],
  textBlocks: TextBlock[]
): Promise<InvoiceData | null> {
  const invoice: Partial<InvoiceData> = {
    lineItems: []
  };
  
  // Fatura numarasÄ±
  const invoiceNumPattern = /fatura\s*(no|numarasÄ±)?[:\s]*([A-Z0-9\-]+)/i;
  for (const block of textBlocks) {
    const match = invoiceNumPattern.exec(block.content);
    if (match) {
      invoice.invoiceNumber = match[2];
      break;
    }
  }
  
  // SatÄ±r kalemleri tablosu bul
  const itemsTable = tables.find(table => {
    const headers = table.headers.map(h => h.toLowerCase());
    return headers.includes('aÃ§Ä±klama') || 
           headers.includes('miktar') || 
           headers.includes('birim fiyat');
  });
  
  if (itemsTable) {
    // Header indekslerini bul
    const descIdx = itemsTable.headers.findIndex(h => 
      h.toLowerCase().includes('aÃ§Ä±klama')
    );
    const qtyIdx = itemsTable.headers.findIndex(h => 
      h.toLowerCase().includes('miktar')
    );
    const priceIdx = itemsTable.headers.findIndex(h => 
      h.toLowerCase().includes('fiyat')
    );
    const totalIdx = itemsTable.headers.findIndex(h => 
      h.toLowerCase().includes('tutar')
    );
    
    // SatÄ±rlarÄ± parse et
    for (const row of itemsTable.rows) {
      if (row.length > Math.max(descIdx, qtyIdx, priceIdx)) {
        invoice.lineItems!.push({
          description: row[descIdx] || '',
          quantity: parseFloat(row[qtyIdx]) || 0,
          unitPrice: parseAmount(row[priceIdx]) || 0,
          total: parseAmount(row[totalIdx]) || 0
        });
      }
    }
  }
  
  // Toplam tutarÄ± bul
  const totalPattern = /toplam[:\s]*([\d.,]+)\s*TL/i;
  for (const block of textBlocks) {
    const match = totalPattern.exec(block.content);
    if (match) {
      invoice.totalAmount = parseAmount(match[1]);
    }
  }
  
  return invoice.invoiceNumber ? invoice as InvoiceData : null;
}

function parseAmount(text: string): number {
  if (!text) return 0;
  // TÃ¼rkÃ§e format: 1.234,56
  const normalized = text
    .replace(/\./g, '')     // Binlik ayracÄ± kaldÄ±r
    .replace(',', '.')      // OndalÄ±k ayracÄ± deÄŸiÅŸtir
    .replace(/[^\d.]/g, ''); // DiÄŸer karakterleri kaldÄ±r
  
  return parseFloat(normalized) || 0;
}
```

### 9.4 Hata Kurtarma ve Retry MekanizmasÄ±

```typescript
// src/lib/utils/resilient-processor.ts
export class ResilientProcessor {
  private retryDelays = [1000, 2000, 5000]; // Exponential backoff
  
  async processWithRetry<T>(
    operation: () => Promise<T>,
    context: {
      operationName: string;
      metadata?: Record<string, any>;
    }
  ): Promise<T> {
    let lastError: Error | null = null;
    
    for (let attempt = 0; attempt <= this.retryDelays.length; attempt++) {
      try {
        AILogger.info(`Attempting ${context.operationName}`, {
          attempt: attempt + 1,
          ...context.metadata
        });
        
        const result = await operation();
        
        if (attempt > 0) {
          AILogger.success(`${context.operationName} succeeded after retry`, {
            attempt: attempt + 1
          });
        }
        
        return result;
      } catch (error) {
        lastError = error as Error;
        
        // BazÄ± hatalar retry edilmemeli
        if (this.isNonRetryableError(error)) {
          AILogger.error(`Non-retryable error in ${context.operationName}`, {
            error: lastError.message
          });
          throw error;
        }
        
        // Son deneme mi?
        if (attempt === this.retryDelays.length) {
          AILogger.error(`${context.operationName} failed after all retries`, {
            attempts: attempt + 1,
            error: lastError.message
          });
          throw error;
        }
        
        // Retry delay
        const delay = this.retryDelays[attempt];
        AILogger.warn(`${context.operationName} failed, retrying in ${delay}ms`, {
          attempt: attempt + 1,
          error: lastError.message
        });
        
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
    
    throw lastError || new Error('Unknown error in processWithRetry');
  }
  
  private isNonRetryableError(error: any): boolean {
    // 4xx hatalar genelde retry edilmemeli
    if (error.status && error.status >= 400 && error.status < 500) {
      return true;
    }
    
    // Belirli hata mesajlarÄ±
    const nonRetryableMessages = [
      'invalid api key',
      'quota exceeded',
      'file too large',
      'unsupported format'
    ];
    
    const errorMessage = error.message?.toLowerCase() || '';
    return nonRetryableMessages.some(msg => errorMessage.includes(msg));
  }
}

// KullanÄ±m
const processor = new ResilientProcessor();

const dataPool = await processor.processWithRetry(
  async () => buildDataPool(files, options),
  {
    operationName: 'buildDataPool',
    metadata: { fileCount: files.length }
  }
);
```

### 9.5 Performans Ä°zleme ve Metrikler

```typescript
// src/lib/monitoring/performance-tracker.ts
export class PerformanceTracker {
  private metrics: Map<string, PerformanceMetric[]> = new Map();
  
  startOperation(operationId: string, metadata?: any): () => void {
    const startTime = performance.now();
    const startMemory = process.memoryUsage();
    
    return () => {
      const duration = performance.now() - startTime;
      const endMemory = process.memoryUsage();
      
      const metric: PerformanceMetric = {
        operationId,
        duration,
        timestamp: new Date(),
        memoryDelta: {
          heapUsed: endMemory.heapUsed - startMemory.heapUsed,
          external: endMemory.external - startMemory.external
        },
        metadata
      };
      
      this.recordMetric(operationId, metric);
    };
  }
  
  private recordMetric(operationId: string, metric: PerformanceMetric) {
    if (!this.metrics.has(operationId)) {
      this.metrics.set(operationId, []);
    }
    
    const metrics = this.metrics.get(operationId)!;
    metrics.push(metric);
    
    // Son 100 metriÄŸi tut
    if (metrics.length > 100) {
      metrics.shift();
    }
    
    // YavaÅŸ operasyonlarÄ± logla
    if (metric.duration > 5000) {
      AILogger.warn('Slow operation detected', {
        operationId,
        duration: `${(metric.duration / 1000).toFixed(2)}s`,
        metadata: metric.metadata
      });
    }
  }
  
  getStats(operationId: string): OperationStats | null {
    const metrics = this.metrics.get(operationId);
    if (!metrics || metrics.length === 0) return null;
    
    const durations = metrics.map(m => m.duration);
    const sorted = [...durations].sort((a, b) => a - b);
    
    return {
      count: metrics.length,
      avg: durations.reduce((a, b) => a + b, 0) / metrics.length,
      min: Math.min(...durations),
      max: Math.max(...durations),
      p50: sorted[Math.floor(sorted.length * 0.5)],
      p95: sorted[Math.floor(sorted.length * 0.95)],
      p99: sorted[Math.floor(sorted.length * 0.99)]
    };
  }
}

// Global instance
export const perfTracker = new PerformanceTracker();

// KullanÄ±m
const endTracking = perfTracker.startOperation('datapool_build', {
  fileCount: files.length,
  totalSize: files.reduce((sum, f) => sum + f.size, 0)
});

try {
  const result = await buildDataPool(files, options);
  return result;
} finally {
  endTracking();
}
```

## Gelecek GeliÅŸtirmeler

### Planlanan Ã–zellikler
- [ ] **Metin OranÄ± KontrolÃ¼**: PDF'de metin oranÄ± <%30 ise otomatik OCR
- [ ] **Session BazlÄ± DataPool**: Her oturum iÃ§in ayrÄ± veri havuzu
- [ ] **Analiz Ä°zlenebilirliÄŸi**: Her AI cevabÄ± `analysis_trace.json` olarak saklanacak
- [ ] **CanlÄ± Durum BarÄ±**: YÃ¼klendi â†’ Analiz Ediliyor â†’ HazÄ±r
- [ ] **Mini Trend GrafiÄŸi**: Son 10 analizin risk skoru ortalamasÄ±
- [ ] **DataPool Versiyonlama**: AynÄ± dosya yeniden analiz edilirse v2 olarak kayÄ±t
- [ ] **Async Queue**: Analizler sÄ±raya alÄ±nÄ±p "Beklemede" etiketi gÃ¶sterilecek
- [ ] **Prompt Versiyonlama**: `prompts/v1.2/` dizininde sÃ¼rÃ¼m kontrolÃ¼

### Teknik Ä°yileÅŸtirmeler
- [ ] WebSocket desteÄŸi ile gerÃ§ek zamanlÄ± gÃ¼ncelleme
- [ ] Distributed processing iÃ§in worker pool
- [ ] GraphQL API alternatifi
- [ ] Elasticsearch entegrasyonu

---

## SonuÃ§

Bu mimari, insan merkezli bir AI analiz sistemi sunarak, kullanÄ±cÄ±larÄ±n her aÅŸamada kontrol sahibi olmalarÄ±nÄ± saÄŸlar. Sistem ÅŸeffaf, denetlenebilir ve geniÅŸletilebilir olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

**Temel prensibimizi unutmayÄ±n**: "AI karar vermez, neden o sonuca vardÄ±ÄŸÄ±nÄ± anlatÄ±r."
